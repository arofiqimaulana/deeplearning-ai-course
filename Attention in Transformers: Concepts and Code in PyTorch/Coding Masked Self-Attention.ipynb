{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58e37a6c-91c7-4875-a8d5-15b16849d8cd",
   "metadata": {},
   "source": [
    "# ðŸŽ¯ Apa Itu Masked Attention?\n",
    "- Masked attention adalah mekanisme untuk mencegah model melihat ke depan (future tokens) saat memproses urutan input.\n",
    "- Biasanya dilakukan dengan masking bagian atas segitiga dari matriks attention (upper triangular matrix), sehingga:\n",
    "    - Saat memproses token ke-i, model hanya bisa \"melihat\" token ke-0 sampai ke-i.\n",
    "    - Token berikutnya disembunyikan (di-masking) dengan -âˆž sebelum softmax."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd3764c-b9d7-402e-b15c-062111b567bd",
   "metadata": {},
   "source": [
    "## Mengapa Perlu Masked Attention?\n",
    "âœ… 1. Agar konsisten dengan cara kita generate teks\n",
    "Transformer decoder digunakan untuk generate satu token demi satu.\n",
    "\n",
    "âœ… 2. Autoregressive consistency\n",
    "Masked attention membuat proses training dan inference konsisten:\n",
    "\n",
    "- Di training, model belajar memprediksi token berikutnya berdasarkan konteks sebelumnya.\n",
    "- Di inference, model memang hanya tahu token sebelumnya.\n",
    "- Tanpa masking, model belajar dari informasi yang tidak akan tersedia saat prediksi nyata dilakukan.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0261c42e-758a-414a-81a3-0dd1a03e3836",
   "metadata": {},
   "source": [
    "## Jika tidak memakai masked self-attention\n",
    "Jika model bisa melihat token ke depan (misalnya dalam konteks self-attention di Transformer tanpa menggunakan masked attention), maka model akan melanggar prinsip kausalitas, yang berarti model akan memiliki informasi yang tidak seharusnya tersedia saat melakukan prediksi. Ini akan berdampak buruk pada kualitas prediksi dan konsistensi selama training maupun inference.\n",
    "\n",
    "Berikut adalah akibat utama jika model bisa melihat token ke depan, beserta contoh nyata:\n",
    "\n",
    "1. Prediksi Tidak Realistis (Cheating)\n",
    "Model akan belajar \"menipu\" dirinya sendiri dengan menggunakan informasi dari masa depan untuk memprediksi token saat ini. Ini tidak realistis dalam konteks banyak aplikasi, seperti generasi teks atau penerjemahan bahasa.\n",
    "\n",
    "2. Overfitting pada Data Training\n",
    "Model yang bisa melihat ke depan akan cenderung terlalu mengandalkan informasi masa depan yang ada di data pelatihan, sehingga tidak dapat generalisasi dengan baik pada data yang tidak terlihat (data testing). Model bisa menjadi terlalu bergantung pada pola yang tidak ada di dunia nyata (karena dalam real-world inference, kita tidak bisa melihat masa depan).\n",
    "\n",
    "3. Kesalahan dalam Prediksi Urutan Teks\n",
    "Banyak aplikasi yang membutuhkan urutan token yang tepat (misalnya, generasi teks atau prediksi kata berikutnya). Jika model dapat melihat ke depan, maka model akan menghasilkan urutan teks yang tidak masuk akal atau tidak koheren.\n",
    "\n",
    "4. Model Tidak Dapat Beroperasi dengan Keterbatasan Seperti Autoregressive Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37a6ed29-60b8-4a9e-8e5e-47eb125e3c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch ## torch let's us create tensors and also provides helper functions\n",
    "import torch.nn as nn ## torch.nn gives us nn.module() and nn.Linear()\n",
    "import torch.nn.functional as F # This gives us the softmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82542dd6-d4e6-47f5-8e8f-97304ff62c2f",
   "metadata": {},
   "source": [
    "## Create Function to Calculate Self-Attention Score\n",
    "$$ Attention(Q,K,V,M) = Softmax(QK^T/\\sqrt{d_k} + M)*V $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "292f5ec1-9176-4e7e-8c72-c0e2c8270c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedSelfAttention(nn.Module): \n",
    "                            \n",
    "    def __init__(self, d_model=2,  \n",
    "                 row_dim=0, \n",
    "                 col_dim=1):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.W_q = nn.Linear(in_features=d_model, out_features=d_model, bias=False)\n",
    "        self.W_k = nn.Linear(in_features=d_model, out_features=d_model, bias=False)\n",
    "        self.W_v = nn.Linear(in_features=d_model, out_features=d_model, bias=False)\n",
    "        \n",
    "        self.row_dim = row_dim\n",
    "        self.col_dim = col_dim\n",
    "\n",
    "        \n",
    "    def forward(self, token_encodings, mask=None):\n",
    "\n",
    "        q = self.W_q(token_encodings)\n",
    "        k = self.W_k(token_encodings)\n",
    "        v = self.W_v(token_encodings)\n",
    "\n",
    "        sims = torch.matmul(q, k.transpose(dim0=self.row_dim, dim1=self.col_dim))\n",
    "\n",
    "        scaled_sims = sims / torch.tensor(k.size(self.col_dim)**0.5)\n",
    "\n",
    "        if mask is not None:\n",
    "            ## Here we are masking out things we don't want to pay attention to\n",
    "            ##\n",
    "            ## We replace values we wanted masked out\n",
    "            ## with a very small negative number so that the SoftMax() function\n",
    "            ## will give all masked elements an output value (or \"probability\") of 0.\n",
    "            scaled_sims = scaled_sims.masked_fill(mask=mask, value=-1e9) # I've also seen -1e20 and -9e15 used in masking\n",
    "\n",
    "        attention_percents = F.softmax(scaled_sims, dim=self.col_dim)\n",
    "\n",
    "        attention_scores = torch.matmul(attention_percents, v)\n",
    "\n",
    "        return attention_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8289769-43f1-4ab3-863e-eabecb6c3745",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "Say it we want to generate a poem with command\n",
    "\n",
    "\"Write a poem\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a859122-9ac8-4d2b-9639-d122373fe204",
   "metadata": {},
   "outputs": [],
   "source": [
    "## using word embedding, we get\n",
    "write = [1.16, 0.23]\n",
    "a = [0.57, 1.36]\n",
    "poem = [4.41, -2.16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d0a4ac3-7934-44aa-b7c5-6aacda93330b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True,  True],\n",
       "        [False, False,  True],\n",
       "        [False, False, False]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create a matrix of token encodings...\n",
    "encodings_matrix = torch.tensor([[1.16, 0.23],\n",
    "                                 [0.57, 1.36],\n",
    "                                 [4.41, -2.16]])\n",
    "\n",
    "## set the seed for the random number generator\n",
    "torch.manual_seed(42)\n",
    "\n",
    "## create a masked self-attention object\n",
    "maskedSelfAttention = MaskedSelfAttention(d_model=2,\n",
    "                               row_dim=0,\n",
    "                               col_dim=1)\n",
    "\n",
    "## create the mask so that we don't use\n",
    "## tokens that come after a token of interest\n",
    "mask = torch.tril(torch.ones(3, 3))\n",
    "mask = mask == 0\n",
    "mask # print out the mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221447d0-e17d-449e-aa5a-95acbaf9eb09",
   "metadata": {},
   "source": [
    "## Calculate Q,K,V,M and Masked Self-Attention Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93b1d890-4422-4a63-b2ea-62c05966c0f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6038,  0.7434],\n",
       "        [-0.0062,  0.6072],\n",
       "        [ 3.4989,  2.2427]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## calculate masked self-attention\n",
    "maskedSelfAttention(encodings_matrix, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fcdd5b0f-ed56-4f71-9225-8b67ae5a1918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5406, -0.1657],\n",
       "        [ 0.5869,  0.6496]], grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## print out the weight matrix that creates the queries\n",
    "maskedSelfAttention.W_q.weight.transpose(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9173a9c9-62ca-440c-b3aa-2bedce593c27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5406, -0.1657],\n",
       "        [ 0.5869,  0.6496]], grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## print out the weight matrix that creates the queries\n",
    "maskedSelfAttention.W_q.weight.transpose(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90b7ffda-618a-40ba-be71-cf5c3971ee01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1549, -0.3443],\n",
       "        [ 0.1427,  0.4153]], grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## print out the weight matrix that creates the keys\n",
    "maskedSelfAttention.W_k.weight.transpose(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb517c25-fda2-4801-9ab3-fa5215859888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6233,  0.6146],\n",
       "        [-0.5188,  0.1323]], grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## print out the weight matrix that creates the values\n",
    "maskedSelfAttention.W_v.weight.transpose(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6bbc88f4-3e54-478e-8f38-363abd1ac0fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7621, -0.0428],\n",
       "        [ 1.1063,  0.7890],\n",
       "        [ 1.1164, -2.1336]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## calculate the queries\n",
    "maskedSelfAttention.W_q(encodings_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab083d7e-5d0b-4596-af8c-55a38df446e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1469, -0.3038],\n",
       "        [ 0.1057,  0.3685],\n",
       "        [-0.9914, -2.4152]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## calculate the keys\n",
    "maskedSelfAttention.W_k(encodings_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be657d30-e816-494e-9b59-c4f7e7eabde7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6038,  0.7434],\n",
       "        [-0.3502,  0.5303],\n",
       "        [ 3.8695,  2.4246]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## calculate the values\n",
    "maskedSelfAttention.W_v(encodings_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0071abec-94c8-4cf4-ac35-77a7bc48f86b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7621, -0.0428],\n",
       "        [ 1.1063,  0.7890],\n",
       "        [ 1.1164, -2.1336]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = maskedSelfAttention.W_q(encodings_matrix)\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e07ce19-8801-4f8c-9adc-2b1e1896fa71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1469, -0.3038],\n",
       "        [ 0.1057,  0.3685],\n",
       "        [-0.9914, -2.4152]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = maskedSelfAttention.W_k(encodings_matrix)\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "68e68cf7-af5b-4cf0-b47f-9c041a633dd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0990,  0.0648, -0.6523],\n",
       "        [-0.4022,  0.4078, -3.0024],\n",
       "        [ 0.4842, -0.6683,  4.0461]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims = torch.matmul(q, k.transpose(dim0=0, dim1=1))\n",
    "sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a672acd-4387-496a-b756-69ae9b68f349",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_sims = sims / (torch.tensor(2)**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ee7fb817-30a6-44d5-9410-1b06fc3ac4a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0700,  0.0458, -0.4612],\n",
       "        [-0.2844,  0.2883, -2.1230],\n",
       "        [ 0.3424, -0.4725,  2.8610]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "26802408-ff15-4c83-a806-42abaa15ff62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-6.9975e-02, -1.0000e+09, -1.0000e+09],\n",
       "        [-2.8442e-01,  2.8833e-01, -1.0000e+09],\n",
       "        [ 3.4241e-01, -4.7253e-01,  2.8610e+00]],\n",
       "       grad_fn=<MaskedFillBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_scaled_sims = scaled_sims.masked_fill(mask=mask, value=-1e9)\n",
    "masked_scaled_sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02ba3ff3-d43c-4330-bcb3-42a31ddc95e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000],\n",
       "        [0.3606, 0.6394, 0.0000],\n",
       "        [0.0722, 0.0320, 0.8959]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_percents = F.softmax(masked_scaled_sims, dim=1)\n",
    "attention_percents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "47bcc07a-f9c9-418e-a05e-19c5d4cf5688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6038,  0.7434],\n",
       "        [-0.0062,  0.6072],\n",
       "        [ 3.4989,  2.2427]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(attention_percents, maskedSelfAttention.W_v(encodings_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c277f4a-e9b7-4c1f-80a2-9276b75ae1ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
